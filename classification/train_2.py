"""
train_simple_classifier.py

–û—á–µ–Ω—å –ø—Ä–æ—Å—Ç–æ–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è ResNet-18 (freeze backbone + train head)
–Ω–∞ –∑–∞–¥–∞—á–µ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ ¬´–≤–∏–∑–∏—Ç–∫–∞ / –Ω–µ‚Äê–≤–∏–∑–∏—Ç–∫–∞¬ª.

Usage:
    python train_simple_classifier.py \
        --data_dir /path/to/dataset \
        --epochs 5 \
        --batch_size 32 \
        --lr 1e-3 \
        --output_model card_classifier_simple.pt
"""

import os
import argparse
import time
from pathlib import Path

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models


def parse_args():
    parser = argparse.ArgumentParser(
        description="Fine‚Äêtune ResNet-18 head for business‚Äêcard detection (2 classes)."
    )
    parser.add_argument(
        "--data_dir", type=str, required=True,
        help="–ü—É—Ç—å –∫ –∫–æ—Ä–Ω—é –¥–∞—Ç–∞—Å–µ—Ç–∞ (–ø–∞–ø–∫–∏ train/ –∏ val/)."
    )
    parser.add_argument(
        "--epochs", type=int, default=5,
        help="–ß–∏—Å–ª–æ —ç–ø–æ—Ö (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 3‚Äì7)."
    )
    parser.add_argument(
        "--batch_size", type=int, default=32,
        help="Batch size –¥–ª—è DataLoader."
    )
    parser.add_argument(
        "--lr", type=float, default=1e-3,
        help="–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –¥–ª—è head‚Äê–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞."
    )
    parser.add_argument(
        "--output_model", type=str, default="card_classifier_simple.pt",
        help="–ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ (.pt)."
    )
    return parser.parse_args()


def train_simple(data_dir: str, epochs: int, batch_size: int, lr: float, output_model: str):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}\n")

    # ======================
    # 1) –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
    # ======================
    data_transforms = {
        "train": transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406],
                                 [0.229, 0.224, 0.225])
        ]),
        "val": transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406],
                                 [0.229, 0.224, 0.225])
        ]),
    }

    # ======================
    # 2) –°–æ–∑–¥–∞—ë–º ImageFolder
    # ======================
    image_datasets = {
        x: datasets.ImageFolder(
            os.path.join(data_dir, x),
            data_transforms[x]
        )
        for x in ["train", "val"]
    }
    dataloaders = {
        x: DataLoader(
            image_datasets[x],
            batch_size=batch_size,
            shuffle=(x == "train"),
            num_workers=4,
            pin_memory=True
        )
        for x in ["train", "val"]
    }
    dataset_sizes = {x: len(image_datasets[x]) for x in ["train", "val"]}
    class_names = image_datasets["train"].classes
    print(f"–ö–ª–∞—Å—Å—ã: {class_names}\n(–æ–∂–∏–¥–∞–µ—Ç—Å—è ['card', 'not_card'])\n")

    # ======================
    # 3) –ó–∞–≥—Ä—É–∂–∞–µ–º ResNet-18
    # ======================
    # pretrained=True ‚Üí —Å–∫–∞—á–∏–≤–∞–µ—Ç –≤–µ—Å–∞ ImageNet
    model = models.resnet18(pretrained=True)
    # –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –í–°–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö —Å–ª–æ–µ–≤
    for param in model.parameters():
        param.requires_grad = False

    # –í–º–µ—Å—Ç–æ fc (512 ‚Üí 1000) —Å—Ç–∞–≤–∏–º –Ω–æ–≤—ã–π —Å–ª–æ–π (512 ‚Üí 2)
    num_ftrs = model.fc.in_features  # –æ–±—ã—á–Ω–æ 512
    model.fc = nn.Linear(num_ftrs, 2)  # 2 –∫–ª–∞—Å—Å–∞: card / not_card

    model = model.to(device)

    # –õ–æ—Å—Å –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä: —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ model.fc
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.fc.parameters(), lr=lr)

    best_val_acc = 0.0

    # ======================
    # 4) –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è
    # ======================
    for epoch in range(epochs):
        print(f"=== –≠–ø–æ—Ö–∞ {epoch+1}/{epochs} ===")
        for phase in ["train", "val"]:
            if phase == "train":
                model.train()
            else:
                model.eval()

            running_loss = 0.0
            running_corrects = 0
            start_time = time.time()

            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                optimizer.zero_grad()

                with torch.set_grad_enabled(phase == "train"):
                    outputs = model(inputs)           # (batch_size, 2)
                    _, preds = torch.max(outputs, 1)  # –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã (0 –∏–ª–∏ 1)
                    loss = criterion(outputs, labels)

                    if phase == "train":
                        loss.backward()
                        optimizer.step()

                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)

            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects.double() / dataset_sizes[phase]
            elapsed = time.time() - start_time

            print(
                f"{phase.capitalize():5s} | "
                f"Loss: {epoch_loss:.4f} | "
                f"Acc: {epoch_acc:.4f} | "
                f"Time: {elapsed:.1f}s"
            )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –ø–æ –º–µ—Ç—Ä–∏–∫–µ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏
            if phase == "val" and epoch_acc > best_val_acc:
                best_val_acc = epoch_acc
                torch.save(model.state_dict(), output_model)
                print(f"  üî• –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å: {output_model} (Val Acc = {best_val_acc:.4f})\n")

    print(f"\n–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. Best Val Acc: {best_val_acc:.4f}")
    print(f"–í–µ—Å—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_model}")


if __name__ == "__main__":
    args = parse_args()
    train_simple(
        data_dir=args.data_dir,
        epochs=args.epochs,
        batch_size=args.batch_size,
        lr=args.lr,
        output_model=args.output_model
    )
